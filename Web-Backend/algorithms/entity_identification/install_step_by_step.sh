#!/bin/bash

# =============================================================================
# Entity Identification é¡¹ç›®ç¯å¢ƒå®‰è£…è„šæœ¬
# åŸºäº Dockerfile å’Œ requirements.txt ç”Ÿæˆ
# =============================================================================

set -e  # é‡åˆ°é”™è¯¯ç«‹å³é€€å‡º

echo "ğŸš€ å¼€å§‹å®‰è£… Entity Identification é¡¹ç›®ç¯å¢ƒ..."
echo "ğŸ“‹ åŸºäº Dockerfile å’Œ requirements.txt é…ç½®"
echo ""

# æ£€æŸ¥Pythonç‰ˆæœ¬
echo "ğŸ” æ£€æŸ¥Pythonç‰ˆæœ¬..."
python3 --version
echo ""

# 1. æ›´æ–°ç³»ç»ŸåŒ…ç®¡ç†å™¨
echo "ï¿½ï¿½ æ­¥éª¤1: æ›´æ–°ç³»ç»ŸåŒ…ç®¡ç†å™¨..."
# sudo apt-get update
echo "âœ… ç³»ç»ŸåŒ…ç®¡ç†å™¨æ›´æ–°å®Œæˆ"
echo ""

# 2. å®‰è£…ç³»ç»Ÿä¾èµ–
echo "ğŸ“¦ æ­¥éª¤2: å®‰è£…ç³»ç»Ÿä¾èµ–..."
# sudo apt-get install -y \
#     libgl1-mesa-glx \
#     libxrender-dev \
#     libglib2.0-0 \
#     wget \
#     curl
echo "âœ… ç³»ç»Ÿä¾èµ–å®‰è£…å®Œæˆ"
echo ""

# 3. æ¸…ç†ç°æœ‰PyTorchå®‰è£…
echo "ğŸ§¹ æ­¥éª¤3: æ¸…ç†ç°æœ‰PyTorchå®‰è£…..."
pip uninstall -y torch torchvision torchaudio || true
echo "âœ… PyTorchæ¸…ç†å®Œæˆ"
echo ""

# 4. å®‰è£…PyTorch (CUDA 11.6ç‰ˆæœ¬)
echo "ğŸ“¦ æ­¥éª¤4: å®‰è£…PyTorch..."
if [ -f "torch-1.13.0+cu116-cp38-cp38-linux_x86_64.whl" ]; then
    echo "ğŸ“ å‘ç°æœ¬åœ°PyTorch wheelæ–‡ä»¶ï¼Œä½¿ç”¨æœ¬åœ°å®‰è£…..."
    pip install torch-1.13.0+cu116-cp38-cp38-linux_x86_64.whl
else
    echo "ğŸŒ ä»ç½‘ç»œå®‰è£…PyTorch..."
    echo "âš ï¸  å°è¯•å®‰è£…CUDA 11.6ç‰ˆæœ¬..."
    pip install torch==1.13.0+cu116 torchvision==0.14.0+cu116 torchaudio==0.13.0+cu116 -f https://download.pytorch.org/whl/torch_stable.html || {
        echo "âš ï¸  CUDA 11.6ç‰ˆæœ¬å®‰è£…å¤±è´¥ï¼Œå°è¯•CUDA 11.7ç‰ˆæœ¬..."
        pip install torch==1.13.0+cu117 torchvision==0.14.0+cu117 torchaudio==0.13.0+cu117 -f https://download.pytorch.org/whl/torch_stable.html || {
            echo "âš ï¸  CUDAç‰ˆæœ¬å®‰è£…å¤±è´¥ï¼Œå®‰è£…CPUç‰ˆæœ¬..."
            pip install torch==1.13.0 torchvision==0.14.0 torchaudio==0.13.0
        }
    }
fi
echo "âœ… PyTorchå®‰è£…å®Œæˆ"
echo ""

# 5. å®‰è£…é¡¹ç›®ä¾èµ–
echo "ğŸ“¦ æ­¥éª¤5: å®‰è£…é¡¹ç›®ä¾èµ–..."
pip install --no-cache-dir -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple
echo "âœ… é¡¹ç›®ä¾èµ–å®‰è£…å®Œæˆ"
echo ""

# 6. å®‰è£…Flask
echo "ğŸ“¦ æ­¥éª¤6: å®‰è£…Flask..."
pip install --trusted-host pypi.python.org Flask
echo "âœ… Flaskå®‰è£…å®Œæˆ"
echo ""

# 7. éªŒè¯å®‰è£…
echo "ğŸ” æ­¥éª¤7: éªŒè¯å®‰è£…..."
echo "æ£€æŸ¥å…³é”®åŒ…ç‰ˆæœ¬:"
python3 -c "
import torch
import transformers
import flask
import numpy
import sklearn
import tqdm

print(f'âœ… PyTorch: {torch.__version__}')
print(f'âœ… Transformers: {transformers.__version__}')
print(f'âœ… Flask: {flask.__version__}')
print(f'âœ… NumPy: {numpy.__version__}')
print(f'âœ… Scikit-learn: {sklearn.__version__}')
print(f'âœ… TQDM: {tqdm.__version__}')
print(f'âœ… CUDAå¯ç”¨: {torch.cuda.is_available()}')
if torch.cuda.is_available():
    print(f'âœ… CUDAç‰ˆæœ¬: {torch.version.cuda}')
    print(f'âœ… GPUæ•°é‡: {torch.cuda.device_count()}')
"
echo ""

# 8. æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
echo "ğŸ” æ­¥éª¤8: æ£€æŸ¥æ¨¡å‹æ–‡ä»¶..."
if [ -d "bert-base-chinese" ]; then
    echo "âœ… å‘ç°ä¸­æ–‡BERTæ¨¡å‹ç›®å½•: bert-base-chinese"
    if [ -f "bert-base-chinese/pytorch_model.bin" ]; then
        echo "âœ… å‘ç°PyTorchæ¨¡å‹æ–‡ä»¶: bert-base-chinese/pytorch_model.bin"
    fi
    if [ -f "bert-base-chinese/model.safetensors" ]; then
        echo "âœ… å‘ç°SafeTensorsæ¨¡å‹æ–‡ä»¶: bert-base-chinese/model.safetensors"
    fi
    if [ -f "bert-base-chinese/config.json" ]; then
        echo "âœ… å‘ç°é…ç½®æ–‡ä»¶: bert-base-chinese/config.json"
    fi
    if [ -f "bert-base-chinese/vocab.txt" ]; then
        echo "âœ… å‘ç°è¯æ±‡è¡¨: bert-base-chinese/vocab.txt"
    fi
else
    echo "âš ï¸  æœªå‘ç°ä¸­æ–‡BERTæ¨¡å‹ç›®å½•: bert-base-chinese"
    echo "   è¯·ç¡®ä¿æ¨¡å‹æ–‡ä»¶å·²æ­£ç¡®æ”¾ç½®"
fi

if [ -d "saved_model-tagger-context" ]; then
    echo "âœ… å‘ç°ä¿å­˜çš„æ¨¡å‹ç›®å½•: saved_model-tagger-context"
else
    echo "âš ï¸  æœªå‘ç°ä¿å­˜çš„æ¨¡å‹ç›®å½•: saved_model-tagger-context"
    echo "   è¯·ç¡®ä¿è®­ç»ƒå¥½çš„æ¨¡å‹å·²æ­£ç¡®æ”¾ç½®"
fi

if [ -d "model" ]; then
    echo "âœ… å‘ç°æ¨¡å‹ä»£ç ç›®å½•: model"
    echo "   åŒ…å«æ–‡ä»¶: $(ls model/ | wc -l) ä¸ªæ–‡ä»¶"
else
    echo "âš ï¸  æœªå‘ç°æ¨¡å‹ä»£ç ç›®å½•: model"
fi
echo ""

# 9. æµ‹è¯•å¯¼å…¥
echo "ï¿½ï¿½ æ­¥éª¤9: æµ‹è¯•å…³é”®æ¨¡å—å¯¼å…¥..."
python3 -c "
try:
    from transformers import AutoTokenizer, AutoModel
    from flask import Flask
    import torch
    import numpy as np
    import sklearn
    import tqdm
    print('âœ… æ‰€æœ‰å…³é”®æ¨¡å—å¯¼å…¥æˆåŠŸ')
except ImportError as e:
    print(f'âŒ æ¨¡å—å¯¼å…¥å¤±è´¥: {e}')
    exit(1)
"
echo ""

# 10. æµ‹è¯•BERTæ¨¡å‹åŠ è½½
echo "ğŸ§ª æ­¥éª¤10: æµ‹è¯•BERTæ¨¡å‹åŠ è½½..."
python3 -c "
try:
    from transformers import AutoTokenizer, AutoModel
    import os
    
    if os.path.exists('bert-base-chinese'):
        print('ğŸ“¥ æµ‹è¯•æœ¬åœ°BERTæ¨¡å‹åŠ è½½...')
        tokenizer = AutoTokenizer.from_pretrained('./bert-base-chinese')
        model = AutoModel.from_pretrained('./bert-base-chinese')
        print('âœ… æœ¬åœ°BERTæ¨¡å‹åŠ è½½æˆåŠŸ')
    else:
        print('âš ï¸  æœ¬åœ°BERTæ¨¡å‹ç›®å½•ä¸å­˜åœ¨ï¼Œè·³è¿‡æµ‹è¯•')
        
except Exception as e:
    print(f'âŒ BERTæ¨¡å‹åŠ è½½æµ‹è¯•å¤±è´¥: {e}')
"
echo ""

echo "ğŸ‰ Entity Identification é¡¹ç›®ç¯å¢ƒå®‰è£…å®Œæˆï¼"
echo ""
echo "ğŸ“‹ å®‰è£…æ€»ç»“:"
echo "   - Python 3.8 ç¯å¢ƒ"
echo "   - PyTorch 1.13.0 (CUDA 11.6)"
echo "   - Transformers 4.27.1"
echo "   - Flask Webæ¡†æ¶"
echo "   - æ‰€æœ‰é¡¹ç›®ä¾èµ–åŒ…"
echo ""
echo "ğŸš€ å¯åŠ¨é¡¹ç›®:"
echo "   python build_api.py"
echo ""
echo "ğŸ“¡ APIç«¯å£: 5012"
echo "ğŸ”— æµ‹è¯•æ¥å£: POST /ner"
echo "ğŸ“ åŠŸèƒ½: å‘½åå®ä½“è¯†åˆ« (NER)"
echo ""
echo "ğŸ“ é¡¹ç›®ç»“æ„:"
echo "   - bert-base-chinese/     : ä¸­æ–‡BERTé¢„è®­ç»ƒæ¨¡å‹"
echo "   - model/                 : æ¨¡å‹ä»£ç "
echo "   - saved_model-tagger-context/ : è®­ç»ƒå¥½çš„æ¨¡å‹"
echo "   - Dataset/               : æ•°æ®é›†"
echo "   - utils/                 : å·¥å…·å‡½æ•°"
echo ""
